{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, create_optimizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"intent_examples_1000_multilingual.xlsx\"\n",
    "df = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Example Query (Spanish)'] = df['Example Query (Spanish)'].str.lstrip('Â¿')\n",
    "df.to_excel(\"cleaned_intent_examples_1000_multilingual.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cleaned_intent_examples_1000_multilingual.xlsx\"\n",
    "ds = pd.read_excel(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting columns\n",
    "df1 = ds[['Example Query (English)', 'Example Query (Arabic)', 'Example Query (Spanish)', 'Intent Category']]\n",
    "df1.columns = ['English', 'Arabic', 'Spanish', 'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data format from wide to long\n",
    "ndf = df1.melt(id_vars = ['Category'], var_name = 'Language', value_name = 'Sample')\n",
    "ndf = ndf[['Sample', 'Category']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.to_excel(\"Final Samples.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Sample        Category\n",
      "0             Play some rock music.       Media (M)\n",
      "1                   Pause the song.       Media (M)\n",
      "2           Skip to the next track.       Media (M)\n",
      "3              Increase the volume.       Media (M)\n",
      "4  Take me to the nearest pharmacy.  Navigation (N)\n"
     ]
    }
   ],
   "source": [
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categories\n",
    "encoder = LabelEncoder()\n",
    "ndf['Category'] = encoder.fit_transform(ndf['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(encoder.classes_)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Play some rock music.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pause the song.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skip to the next track.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Increase the volume.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Take me to the nearest pharmacy.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Sample  Category\n",
       "0             Play some rock music.         4\n",
       "1                   Pause the song.         4\n",
       "2           Skip to the next track.         4\n",
       "3              Increase the volume.         4\n",
       "4  Take me to the nearest pharmacy.         5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(samples, categories):\n",
    "\n",
    "    encodings = tokenizer(samples.tolist(), padding = True, truncation = True, return_tensors = 'tf')\n",
    "    return encodings, tf.keras.utils.to_categorical(categories, num_classes = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples, train_categories, test_categories = train_test_split(ndf['Sample'], ndf['Category'], test_size = 0.2, random_state = 41, shuffle = True)\n",
    "train_encodings, train_categories = tokenize_function(train_samples, train_categories)\n",
    "test_encodings, test_categories = tokenize_function(test_samples, test_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": train_encodings[\"input_ids\"], \"attention_mask\": train_encodings[\"attention_mask\"]}, train_categories)).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(({\"input_ids\": test_encodings[\"input_ids\"], \"attention_mask\": test_encodings[\"attention_mask\"]}, test_categories)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = len(train_dataset) * 10\n",
    "optimizer, schedule = create_optimizer(init_lr = 3e-5, num_warmup_steps = 0, num_train_steps = training_steps)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(name = 'accuracy'), \n",
    "           tf.keras.metrics.Precision(name = 'precision'),\n",
    "           tf.keras.metrics.Recall(name = 'recall')]\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 182s 1s/step - loss: 1.1731 - accuracy: 0.7358 - precision: 0.6819 - recall: 0.6733 - val_loss: 0.1344 - val_accuracy: 1.0000 - val_precision: 0.9788 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 155s 1s/step - loss: 0.0746 - accuracy: 1.0000 - precision: 0.9881 - recall: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 148s 988ms/step - loss: 0.0252 - accuracy: 1.0000 - precision: 0.9992 - recall: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 146s 976ms/step - loss: 0.0142 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 145s 965ms/step - loss: 0.0095 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 147s 980ms/step - loss: 0.0072 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 148s 989ms/step - loss: 0.0059 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 144s 959ms/step - loss: 0.0051 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 146s 974ms/step - loss: 0.0046 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 146s 976ms/step - loss: 0.0043 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x192d82f39e0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data = test_dataset, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 7s 175ms/step - loss: 0.0029 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Test Loss: 0.0028826287016272545\n",
      "Test Accuracy: 1.0\n",
      "Test Precision: 1.0\n",
      "Test Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 9s 184ms/step\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 0, True: 0\n",
      "Predicted: 2, True: 2\n",
      "Predicted: 3, True: 3\n",
      "Predicted: 1, True: 1\n",
      "Predicted: 7, True: 7\n",
      "Predicted: 6, True: 6\n",
      "Predicted: 4, True: 4\n",
      "Predicted: 0, True: 0\n"
     ]
    }
   ],
   "source": [
    "true_labels = tf.argmax(test_categories, axis = -1).numpy()\n",
    "true_labels = encoder.inverse_transform(true_labels)    \n",
    "\n",
    "prediction = model.predict(test_dataset)\n",
    "\n",
    "predicted_labels = tf.argmax(prediction.logits, axis = -1).numpy()\n",
    "predicted_labels = encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Predicted: {predicted_labels[i]}, True: {true_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing new sample\n",
    "sample = [\"Can u tell me a wise saying?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoding = tokenizer(sample, padding = True, truncation = True, return_tensors = \"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(sample_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    }
   ],
   "source": [
    "probabilities = tf.nn.softmax(predictions.logits, axis = -1).numpy()\n",
    "predicted = np.argmax(probabilities, axis = -1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, 512), tf.int32, name = \"input_ids\"), tf.TensorSpec((None, 512), tf.int32, name = \"attention_mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxModel, _ = tf2onnx.convert.from_keras(model, input_signature = spec, opset = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnxModel, \"intentDetection.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDT = onnx.load(\"intentDetection.onnx\")\n",
    "onnx.checker.check_model(IDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
